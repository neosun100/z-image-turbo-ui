{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Z-Image-Turbo: Text-to-Image Generation\n",
    "\n",
    "This notebook provides a simple interface to generate images using the **Tongyi-MAI/Z-Image-Turbo** model.\n",
    "\n",
    "- **Model**: 6B-parameter text-to-image generation model\n",
    "- **Speed**: Lightning-fast inference (optimized for 8-step generation)\n",
    "- **Resolution**: Supports up to 2048×2048 (2MP)\n",
    "- **Languages**: English and Chinese text rendering\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install-header"
   },
   "source": [
    "## 1. Install Dependencies\n",
    "\n",
    "Install required packages including diffusers from source (required for ZImagePipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "!pip install -q torch transformers accelerate protobuf sentencepiece\n",
    "!pip install -q git+https://github.com/huggingface/diffusers.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "load-header"
   },
   "source": [
    "## 2. Load Model\n",
    "\n",
    "Load the Z-Image-Turbo pipeline. This will download the model on first run (~12GB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load-model"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import ZImagePipeline\n",
    "from IPython.display import display\n",
    "\n",
    "# Load the pipeline\n",
    "print(\"Loading Z-Image-Turbo model...\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.bfloat16 if device == \"cuda\" else torch.float32\n",
    "\n",
    "pipe = ZImagePipeline.from_pretrained(\n",
    "    \"Tongyi-MAI/Z-Image-Turbo\",\n",
    "    torch_dtype=dtype,\n",
    "    low_cpu_mem_usage=False\n",
    ")\n",
    "pipe.to(device)\n",
    "\n",
    "print(f\"Model loaded successfully on {device}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config-header"
   },
   "source": [
    "## 3. Configure Generation Parameters\n",
    "\n",
    "Set your prompt and generation parameters here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "configure"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# GENERATION PARAMETERS - Edit these!\n",
    "# ============================================\n",
    "\n",
    "# Your text prompt\n",
    "prompt = \"A serene landscape with mountains and a lake at sunset, highly detailed, 4k\"\n",
    "\n",
    "# Image dimensions (must be divisible by 16)\n",
    "width = 1024\n",
    "height = 1024\n",
    "\n",
    "# Generation settings\n",
    "steps = 8              # Number of inference steps (1-50, default: 8)\n",
    "guidance_scale = 0.0   # Guidance scale (0-10, default: 0.0)\n",
    "seed = -1              # Seed for reproducibility (-1 for random)\n",
    "\n",
    "# ============================================\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Resolution: {width}×{height}\")\n",
    "print(f\"Steps: {steps}, Guidance: {guidance_scale}, Seed: {seed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "generate-header"
   },
   "source": [
    "## 4. Generate and Display Image\n",
    "\n",
    "Run this cell to generate the image based on your prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "generate"
   },
   "outputs": [],
   "source": [
    "# Validate dimensions\n",
    "if height % 16 != 0 or width % 16 != 0:\n",
    "    raise ValueError(\"Height and Width must be divisible by 16\")\n",
    "\n",
    "# Set up generator for reproducibility\n",
    "generator = None\n",
    "if seed != -1:\n",
    "    generator = torch.Generator(device).manual_seed(seed)\n",
    "\n",
    "# Generate image\n",
    "print(\"Generating image...\")\n",
    "image = pipe(\n",
    "    prompt=prompt,\n",
    "    height=height,\n",
    "    width=width,\n",
    "    num_inference_steps=steps,\n",
    "    guidance_scale=guidance_scale,\n",
    "    generator=generator,\n",
    ").images[0]\n",
    "\n",
    "print(\"Done! Displaying image...\")\n",
    "\n",
    "# Display the generated image\n",
    "display(image)\n",
    "\n",
    "# Optionally save the image\n",
    "output_filename = \"generated_image.png\"\n",
    "image.save(output_filename)\n",
    "print(f\"Image saved as: {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "presets-header"
   },
   "source": [
    "## 5. Common Presets (Optional)\n",
    "\n",
    "Here are some common resolution presets you can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "presets"
   },
   "outputs": [],
   "source": [
    "# Uncomment the preset you want to use, then re-run the generation cell\n",
    "\n",
    "# Square formats\n",
    "# width, height = 512, 512      # Standard square\n",
    "# width, height = 768, 768      # Medium square\n",
    "# width, height = 1024, 1024    # Large square (default)\n",
    "\n",
    "# Portrait formats (3:4)\n",
    "# width, height = 896, 1152\n",
    "\n",
    "# Landscape formats (4:3)\n",
    "# width, height = 1152, 896\n",
    "\n",
    "# Widescreen formats (16:9)\n",
    "# width, height = 1344, 768\n",
    "# width, height = 1280, 720     # HD\n",
    "# width, height = 1920, 1088    # Full HD\n",
    "\n",
    "print(f\"Current resolution: {width}×{height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tips-header"
   },
   "source": [
    "## Tips for Best Results\n",
    "\n",
    "1. **Prompt Writing**: Be descriptive and specific. Include style keywords like \"highly detailed\", \"4k\", \"photorealistic\", etc.\n",
    "2. **Steps**: The model is optimized for 8 steps, but you can experiment with 4-20 steps.\n",
    "3. **Guidance Scale**: Start with 0.0 (default). Increase if you want stronger prompt adherence.\n",
    "4. **Seed**: Use a specific seed (e.g., 42) to reproduce the same image with the same parameters.\n",
    "5. **Resolution**: Higher resolutions require more VRAM. Start with 1024×1024 on most GPUs.\n",
    "\n",
    "---\n",
    "\n",
    "## Model Information\n",
    "\n",
    "- **Model ID**: Tongyi-MAI/Z-Image-Turbo\n",
    "- **Architecture**: S3-DiT (Scalable Single-Stream Diffusion Transformer)\n",
    "- **Text Encoder**: Qwen 4B LLM\n",
    "- **License**: Apache 2.0\n",
    "- **GitHub**: [https://github.com/Aaryan-Kapoor/z-image-turbo](https://github.com/Aaryan-Kapoor/z-image-turbo)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
